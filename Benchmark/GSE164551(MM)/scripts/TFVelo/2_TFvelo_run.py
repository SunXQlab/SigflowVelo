import pandas as pd    
import TFvelo as TFv
import anndata as ad
import numpy as np
import scanpy as sc
import scvelo as scv
import matplotlib
matplotlib.use('AGG')

import os, sys

def check_data_type(adata):
    """Check and convert string boolean values to actual boolean values"""
    for key in list(adata.var):
        if adata.var[key][0] in ['True', 'False']:
            adata.var[key] = adata.var[key].map({'True': True, 'False': False})
    return          

def data_type_tostr(adata, key):
    """Convert boolean values to string representation"""
    if key in adata.var.keys():
        if adata.var[key][0] in [True, False]:
            adata.var[key] = adata.var[key].map({True: 'True', False:'False'})
    return          

def preprocess(args):
    """Data preprocessing for different datasets"""
    print('----------------------------------preprocess', args.dataset_name, '---------------------------------------------')
    
    # Create output directory
    os.makedirs(args.result_path, exist_ok=True)
    
    if args.dataset_name == 'Multi_myeloma_NK':
        # Read the data file generated by the previous R script
        adata = ad.read_h5ad("output/data/Multi_myeloma_NK.h5ad") 
    
        # 1. Core: Create TFvelo required "total" expression matrix layer
        if 'logcounts' in adata.layers:
            adata.layers['total'] = adata.layers['logcounts'].copy()
        elif 'count' in adata.layers:
            adata.layers['total'] = adata.layers['count'].copy()
        else:
            adata.layers['total'] = adata.X.copy()
        
        # 2. Unify cell clustering/type information column name (TFvelo requires 'clusters')
        if 'celltype' in adata.obs.columns:
            adata.obs['clusters'] = adata.obs['celltype'].astype('category')
        elif 'seurat_clusters' in adata.obs.columns:
            adata.obs['clusters'] = 'Cluster_' + adata.obs['seurat_clusters'].astype(str)
            adata.obs['clusters'] = adata.obs['clusters'].astype('category')
        else:
            print("Warning: No clear cell type information found")
        
        # 3. Unify dimension reduction coordinate key names
        if 'PCA' in adata.obsm:
            adata.obsm['X_pca'] = adata.obsm.pop('PCA')
        if 'TSNE' in adata.obsm:
            adata.obsm['X_tsne'] = adata.obsm.pop('TSNE')
        if 'UMAP' in adata.obsm:
            adata.obsm['X_umap'] = adata.obsm.pop('UMAP')
        
        if 'X_pca' in adata.obsm:
            x_pca_data = adata.obsm['X_pca']
            # Check and convert
            if hasattr(x_pca_data, 'values') and not isinstance(x_pca_data, np.ndarray):
                # If DataFrame or similar object with .values attribute, convert to NumPy array
                adata.obsm['X_pca'] = x_pca_data.values.astype(np.float32)  # Specify float type
                print("Converted 'X_pca' to NumPy array")
        
        # 4. Add a simple color scheme (for visualization)
        import matplotlib.pyplot as plt
        n_clusters = len(adata.obs['clusters'].cat.categories)
        cmap = plt.cm.tab20  # Use matplotlib tab20 colormap
        colors = [cmap(i % 20) for i in range(n_clusters)]  # Cycle colors
        adata.uns['clusters_colors'] = np.array(colors, dtype=object) 
    
    elif args.dataset_name == 'pancreas':
        adata = scv.datasets.pancreas() 
    
    elif args.dataset_name == 'gastrulation_erythroid':
        adata = scv.datasets.gastrulation_erythroid()   
        adata.uns['clusters_colors'] = adata.uns['celltype_colors'].copy()
        adata.obs['clusters'] = adata.obs['celltype'].copy()
    
    elif args.dataset_name == 'hesc1':
        expression = pd.read_table("data/hesc1/rpkm.txt", header=0, index_col=0, sep="\t").T 
        adata = ad.AnnData(expression)
        adata.obs_names = expression.index
        adata.var_names = expression.columns
        adata.obs['time_gt'] = 'Nan'
        
        for ii, cell in enumerate(adata.obs_names):
            adata.obs['time_gt'][ii] = cell.split('.')[0]
        
        adata.obs['time_gt'] = adata.obs['time_gt'].astype('category') 
        adata.obs['clusters'] = adata.obs['time_gt'].copy()
    
    elif args.dataset_name == '10x_mouse_brain':
        adata = ad.read_h5ad("data/10x_mouse_brain/adata_rna.h5ad")  
        adata.obs['clusters'] = adata.obs['celltype'].copy()   

    # Ensure unique names
    adata.var_names_make_unique()
    adata.obs_names_make_unique()

    # Store all gene names
    adata.uns['genes_all'] = np.array(adata.var_names)

    # Create total expression layer
    if "spliced" in adata.layers:
        adata.layers["total"] = adata.layers["spliced"].todense() + adata.layers["unspliced"].todense()
    elif "new" in adata.layers:
        adata.layers["total"] = np.array(adata.layers["total"].todense())
    else:
        adata.layers["total"] = adata.X
    
    adata.layers["total_raw"] = adata.layers["total"].copy()
    
    # Filter genes and cells
    n_cells, n_genes = adata.X.shape
    sc.pp.filter_genes(adata, min_cells=int(n_cells/50))
    sc.pp.filter_cells(adata, min_genes=int(n_genes/50))
    
    # TFvelo preprocessing
    TFv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=2000, log=True)
    adata.X = adata.layers["total"].copy()

    # Set colors if not 10x_mouse_brain dataset
    if not args.dataset_name in ['10x_mouse_brain']:
        adata.uns['clusters_colors'] = np.array([
            'red', 'orange', 'yellow', 'green', 'skyblue', 'blue', 'purple', 'pink', 
            '#8fbc8f', '#f4a460', '#fdbf6f', '#ff7f00', '#b2df8a', '#1f78b4',
            '#6a3d9a', '#cab2d6'
        ], dtype=object)

    # Convert gene names to uppercase
    gene_names = []
    for tmp in adata.var_names:
        gene_names.append(tmp.upper())
    adata.var_names = gene_names
    adata.var_names_make_unique()
    adata.obs_names_make_unique()

    # Compute moments
    TFv.pp.moments(adata, n_pcs=30, n_neighbors=args.n_neighbors)

    # Get transcription factors
    TFv.pp.get_TFs(adata, databases=args.TF_databases)
    print(adata)
    
    # Store processed gene names
    adata.uns['genes_pp'] = np.array(adata.var_names)
    
    # Save preprocessed data
    adata.write(args.result_path + 'pp.h5ad')

def main(args):
    """Main analysis function"""
    print('--------------------------------')
    
    # Load preprocessed data
    adata = ad.read_h5ad(args.result_path + 'pp.h5ad')
    n_jobs = args.n_jobs
    
    print('n_jobs:', n_jobs)
    
    # Recover dynamics
    flag = TFv.tl.recover_dynamics(
        adata, 
        n_jobs=n_jobs, 
        max_iter=args.max_iter, 
        var_names=args.var_names,
        WX_method=args.WX_method, 
        WX_thres=args.WX_thres, 
        max_n_TF=args.max_n_TF, 
        n_top_genes=args.n_top_genes,
        fit_scaling=True, 
        use_raw=args.use_raw, 
        init_weight_method=args.init_weight_method, 
        n_time_points=args.n_time_points
    ) 
    
    if flag == False:
        return adata, False
    
    # Convert boolean data types to string if needed
    if 'highly_variable_genes' in adata.var.keys():
        data_type_tostr(adata, key='highly_variable_genes')
    
    # Save recovered dynamics data
    adata.write(args.result_path + 'rc.h5ad')
    return

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset_name', type=str, default='Multi_myeloma_NK', 
                       help='pancreas, gastrulation_erythroid, 10x_mouse_brain, hesc1') 
    parser.add_argument('--n_jobs', type=int, default=6, help='number of cpus to use')
    parser.add_argument('--var_names', type=str, default="all", help='all, highly_variable_genes')
    parser.add_argument('--init_weight_method', type=str, default="correlation", 
                       help='use correlation to initialize the weights')
    parser.add_argument('--WX_method', type=str, default="lsq_linear", 
                       help='LS, LASSO, Ridge, constant, LS_constrant, lsq_linear')
    parser.add_argument('--n_neighbors', type=int, default=10, help='number of neighbors')
    parser.add_argument('--WX_thres', type=int, default=5, help='the threshold for weights')
    parser.add_argument('--n_top_genes', type=int, default=500, help='n_top_genes')
    parser.add_argument('--TF_databases', nargs='+', default='ENCODE ChEA', 
                       help='knockTF ChEA ENCODE')
    parser.add_argument('--max_n_TF', type=int, default=30, help='max number of TFs')
    parser.add_argument('--max_iter', type=int, default=5, help='max number of iteration in EM')
    parser.add_argument('--n_time_points', type=int, default=1000, help='use_raw')
    parser.add_argument('--save_name', type=str, default='_demo', help='save_name')
    parser.add_argument('--use_raw', type=int, default=0, help='use_raw')
    parser.add_argument('--basis', type=str, default='umap', help='umap')

    args = parser.parse_args() 
    
    # Set result path (preserving original saving path rules)
    args.result_path = 'TFvelo_' + args.dataset_name + args.save_name + '/'
    
    print('********************************************************************************************************')
    print('********************************************************************************************************')  
    print(args)
    
    # Run preprocessing and main analysis
    preprocess(args)  
    main(args)